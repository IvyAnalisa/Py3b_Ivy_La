{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30123cb-22c6-417e-bd58-0914f18bc81f",
   "metadata": {},
   "source": [
    "### 2. Load or generate the data that you want to use to train the model and split it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82c8c88-5eac-4fed-87a9-05ff21e6d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (X_train): (120, 4)\n",
      "Testing set size (X_test): (30, 4)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Required for part 2\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = iris.data  \n",
    "y = iris.target  \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(f\"Training set size (X_train): {X_train.shape}\")\n",
    "print(f\"Testing set size (X_test): {X_test.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873ff2b-a9ac-44ad-ae96-80d64b2397c4",
   "metadata": {},
   "source": [
    "### 3. Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5cf4c7-c795-4c25-b193-17124f2998bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (X_train): (120, 4)\n",
      "Testing set size (X_test): (30, 4)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Required for part 2\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = iris.data  \n",
    "y = iris.target \n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(f\"Training set size (X_train): {X_train.shape}\")\n",
    "print(f\"Testing set size (X_test): {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ae794-56c3-4173-99b7-f0004057b987",
   "metadata": {},
   "source": [
    "### 4. Create an instance of the DecisionTreeRegressor class and fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f5043f2-788b-40e5-beaf-a1a519cbabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "# Train the model on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8615d52-1257-4e6f-8167-651bcf99141d",
   "metadata": {},
   "source": [
    "### 5. Make predictions on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff3f9680-8f7a-4124-b623-770dd4cbb320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the testing set: 0.97\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the testing set: {accuracy:.2f}\")\n",
    "\n",
    "# Display a more detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cde081-69d7-4108-bd7e-ad0a9aa0b913",
   "metadata": {},
   "source": [
    "### 6. Evaluate the performance of the model using accuracy, precision, recall, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6df84686-9f83-44ac-85ab-971e38c7b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Precision: 0.9700000000000001\n",
      "Recall: 0.9666666666666667\n",
      "F1 Score: 0.9665634674922601\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Required for part 2\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = iris.data  # Feature matrix (sepal/petal length/width)\n",
    "y = iris.target  # Target labels (species)\n",
    "\n",
    "# Calculate metrics such as accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6288a-6581-4db7-aeb9-c2554bbf3da9",
   "metadata": {},
   "source": [
    "## Red Wine Quality assigments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a41402-6936-47fb-a14c-bb750034e87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n",
      "\n",
      "Descriptive statistics of the dataset:\n",
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
      "mean        8.319637          0.527821     0.270976        2.538806   \n",
      "std         1.741096          0.179060     0.194801        1.409928   \n",
      "min         4.600000          0.120000     0.000000        0.900000   \n",
      "25%         7.100000          0.390000     0.090000        1.900000   \n",
      "50%         7.900000          0.520000     0.260000        2.200000   \n",
      "75%         9.200000          0.640000     0.420000        2.600000   \n",
      "max        15.900000          1.580000     1.000000       15.500000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
      "mean      0.087467            15.874922             46.467792     0.996747   \n",
      "std       0.047065            10.460157             32.895324     0.001887   \n",
      "min       0.012000             1.000000              6.000000     0.990070   \n",
      "25%       0.070000             7.000000             22.000000     0.995600   \n",
      "50%       0.079000            14.000000             38.000000     0.996750   \n",
      "75%       0.090000            21.000000             62.000000     0.997835   \n",
      "max       0.611000            72.000000            289.000000     1.003690   \n",
      "\n",
      "                pH    sulphates      alcohol      quality  \n",
      "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
      "mean      3.311113     0.658149    10.422983     5.636023  \n",
      "std       0.154386     0.169507     1.065668     0.807569  \n",
      "min       2.740000     0.330000     8.400000     3.000000  \n",
      "25%       3.210000     0.550000     9.500000     5.000000  \n",
      "50%       3.310000     0.620000    10.200000     6.000000  \n",
      "75%       3.400000     0.730000    11.100000     6.000000  \n",
      "max       4.010000     2.000000    14.900000     8.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('winequality-red.csv')  \n",
    "\n",
    "# Explore the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())  # Show the first 5 rows\n",
    "\n",
    "# Get a summary of the dataset (including count, mean, std, min, max, etc.)\n",
    "print(\"\\nDescriptive statistics of the dataset:\")\n",
    "print(df.describe())  # show statistics for numerical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf13249-0451-49d6-8f3e-483930d479ed",
   "metadata": {},
   "source": [
    "### 2. Prepare the data by extracting features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c42154-39df-4406-a70e-1b64a6bd42d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n",
      "Shape of features (X): (1599, 11)\n",
      "Shape of labels (y): (1599,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('winequality-red.csv')  \n",
    "\n",
    "# Explore the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())  # Show the first 5 rows\n",
    "\n",
    "# Extract features (X) by dropping the 'quality' column\n",
    "X = df.drop('quality', axis=1)\n",
    "\n",
    "# Extract labels (y) by selecting the 'quality' column\n",
    "y = df['quality']\n",
    "\n",
    "# Print the shapes of X and y to validate the result\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "print(\"Shape of labels (y):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123828b4-b949-483a-9374-86502e54d4b3",
   "metadata": {},
   "source": [
    "### 3. Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6311fc39-6fc8-4c37-860f-25c807d00637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n",
      "Shape of X_train: (1279, 11)\n",
      "Shape of X_test: (320, 11)\n",
      "Shape of y_train: (1279,)\n",
      "Shape of y_test: (320,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('winequality-red.csv')  # Adjust the file name if necessary\n",
    "\n",
    "# Explore the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())  # Show the first 5 rows\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the resulting sets to verify\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59450a21-3e8d-48d3-9e88-fdfef1bef581",
   "metadata": {},
   "source": [
    "\n",
    " # Assignments 4,5,6,7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b6a6f-ed95-4b6e-84de-edecea18e945",
   "metadata": {},
   "source": [
    "### 4. Create an instance of the DecisionTreeRegressor class and fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc771ab9-1600-4892-864b-a3fae72b05d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor has been trained. Training MSE: 0.0000\n",
      "Support Vector Classifier has been trained. Training Accuracy: 0.5103\n",
      "K-Nearest Neighbors Classifier has been trained. Training Accuracy: 0.6693\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset \n",
    "df = pd.read_csv('winequality-red.csv')  # Adjust the file name if necessary\n",
    "\n",
    "# Create instances of each model\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "svc_classifier = SVC(random_state=42)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Fit each model to the training data\n",
    "dt_regressor.fit(X_train, y_train)  # Training Decision Tree Regressor\n",
    "svc_classifier.fit(X_train, y_train)  # Training Support Vector Classifier\n",
    "knn_classifier.fit(X_train, y_train)  # Training K-Nearest Neighbors Classifier\n",
    "\n",
    "# Evaluate Decision Tree Regressor (training MSE)\n",
    "dt_train_predictions = dt_regressor.predict(X_train)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_train_predictions)\n",
    "print(f\"Decision Tree Regressor has been trained. Training MSE: {dt_train_mse:.4f}\")# .4f is  4 digits after the decimal point\n",
    "\n",
    "# Evaluate Support Vector Classifier (training accuracy)\n",
    "svc_train_predictions = svc_classifier.predict(X_train)\n",
    "svc_train_accuracy = accuracy_score(y_train, svc_train_predictions)\n",
    "print(f\"Support Vector Classifier has been trained. Training Accuracy: {svc_train_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate K-Nearest Neighbors Classifier (training accuracy)\n",
    "knn_train_predictions = knn_classifier.predict(X_train)\n",
    "knn_train_accuracy = accuracy_score(y_train, knn_train_predictions)\n",
    "print(f\"K-Nearest Neighbors Classifier has been trained. Training Accuracy: {knn_train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc3c63-e4eb-486d-8b3f-88fd3857c6d7",
   "metadata": {},
   "source": [
    "### 5. Make predictions on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccd128d9-21d3-4c21-8af9-dd18d033760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Predictions: [5 4 5 6 6]\n",
      "Support Vector Classifier Predictions: [5 5 6 6 6]\n",
      "K-Nearest Neighbors Classifier Predictions: [5 5 6 5 6]\n",
      "\n",
      "Decision Tree Classifier Evaluation:\n",
      "Accuracy: 0.5729166666666666\n",
      "Confusion Matrix:\n",
      " [[  0   0   1   0   0   0]\n",
      " [  0   1  10   5   1   0]\n",
      " [  1   8 126  58   2   0]\n",
      " [  0   5  48 121  26   0]\n",
      " [  0   1   6  26  26   2]\n",
      " [  0   0   0   3   2   1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.07      0.06      0.06        17\n",
      "           5       0.66      0.65      0.65       195\n",
      "           6       0.57      0.60      0.59       200\n",
      "           7       0.46      0.43      0.44        61\n",
      "           8       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.57       480\n",
      "   macro avg       0.35      0.32      0.33       480\n",
      "weighted avg       0.57      0.57      0.57       480\n",
      "\n",
      "\n",
      "Support Vector Classifier Evaluation:\n",
      "Accuracy: 0.5041666666666667\n",
      "Confusion Matrix:\n",
      " [[  0   0   0   1   0   0]\n",
      " [  0   0   3  14   0   0]\n",
      " [  0   0  99  96   0   0]\n",
      " [  0   0  58 142   0   0]\n",
      " [  0   0   5  55   1   0]\n",
      " [  0   0   1   5   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.60      0.51      0.55       195\n",
      "           6       0.45      0.71      0.55       200\n",
      "           7       1.00      0.02      0.03        61\n",
      "           8       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50       480\n",
      "   macro avg       0.34      0.21      0.19       480\n",
      "weighted avg       0.56      0.50      0.46       480\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classifier Evaluation:\n",
      "Accuracy: 0.48541666666666666\n",
      "Confusion Matrix:\n",
      " [[  0   0   1   0   0   0]\n",
      " [  0   1   7   9   0   0]\n",
      " [  0   1 126  64   4   0]\n",
      " [  0   2  89  97  12   0]\n",
      " [  0   0  18  34   9   0]\n",
      " [  0   0   1   4   1   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.25      0.06      0.10        17\n",
      "           5       0.52      0.65      0.58       195\n",
      "           6       0.47      0.48      0.48       200\n",
      "           7       0.35      0.15      0.21        61\n",
      "           8       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.49       480\n",
      "   macro avg       0.26      0.22      0.23       480\n",
      "weighted avg       0.46      0.49      0.46       480\n",
      "\n",
      "\n",
      "Class distribution in y_test (Decision Tree):\n",
      "quality\n",
      "6    200\n",
      "5    195\n",
      "7     61\n",
      "4     17\n",
      "8      6\n",
      "3      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in y_pred (Decision Tree):\n",
      "6    213\n",
      "5    191\n",
      "7     57\n",
      "4     15\n",
      "8      3\n",
      "3      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in y_test (SVC):\n",
      "quality\n",
      "6    200\n",
      "5    195\n",
      "7     61\n",
      "4     17\n",
      "8      6\n",
      "3      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in y_pred (SVC):\n",
      "6    313\n",
      "5    166\n",
      "7      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in y_test (KNN):\n",
      "quality\n",
      "6    200\n",
      "5    195\n",
      "7     61\n",
      "4     17\n",
      "8      6\n",
      "3      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in y_pred (KNN):\n",
      "5    242\n",
      "6    208\n",
      "7     26\n",
      "4      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset \n",
    "df = pd.read_csv('winequality-red.csv')  \n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 5. Make predictions on the testing set\n",
    "# For Decision Tree Classifier\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# For Support Vector Classifier\n",
    "y_pred_svc = svc_classifier.predict(X_test)\n",
    "\n",
    "# For K-Nearest Neighbors Classifier\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# Print the first few predictions to verify\n",
    "print(\"Decision Tree Regressor Predictions:\", y_pred_dt[:5]) \n",
    "print(\"Support Vector Classifier Predictions:\", y_pred_svc[:5])\n",
    "print(\"K-Nearest Neighbors Classifier Predictions:\", y_pred_knn[:5])\n",
    "# Using [:5] ensures only the first five predictions are shown\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt, zero_division=0))\n",
    "\n",
    "# Evaluate Support Vector Classifier\n",
    "print(\"\\nSupport Vector Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svc))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svc, zero_division=0))\n",
    "\n",
    "# Evaluate K-Nearest Neighbors Classifier\n",
    "print(\"\\nK-Nearest Neighbors Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn, zero_division=0))\n",
    "\n",
    "\n",
    "\n",
    "# For Decision Tree Classifier\n",
    "print(\"\\nClass distribution in y_test (Decision Tree):\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution in y_pred (Decision Tree):\")\n",
    "print(pd.Series(y_pred_dt).value_counts())\n",
    "\n",
    "# For Support Vector Classifier (SVC)\n",
    "print(\"\\nClass distribution in y_test (SVC):\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution in y_pred (SVC):\")\n",
    "print(pd.Series(y_pred_svc).value_counts())\n",
    "\n",
    "# For K-Nearest Neighbors Classifier (KNN)\n",
    "print(\"\\nClass distribution in y_test (KNN):\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution in y_pred (KNN):\")\n",
    "print(pd.Series(y_pred_knn).value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b0d3f-eb4e-46af-91e0-0b69f674237e",
   "metadata": {},
   "source": [
    "### 6. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c9bf0b0-5fbd-4dde-8749-f79d6031f114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier Evaluation:\n",
      "Accuracy: 0.57\n",
      "Precision: 0.57\n",
      "Recall: 0.57\n",
      "F1 Score: 0.57\n",
      "\n",
      "Support Vector Classifier Evaluation:\n",
      "Accuracy: 0.50\n",
      "Precision: 0.61\n",
      "Recall: 0.50\n",
      "F1 Score: 0.46\n",
      "\n",
      "K-Nearest Neighbors Classifier Evaluation:\n",
      "Accuracy: 0.49\n",
      "Precision: 0.47\n",
      "Recall: 0.49\n",
      "F1 Score: 0.46\n",
      "\n",
      " Model Comparison:\n",
      "Decision Tree Classifier - Accuracy: 0.5729, Precision: 0.5692, Recall: 0.5729, F1: 0.5704\n",
      "Support Vector Classifier - Accuracy: 0.5042, Precision: 0.4733, Recall: 0.5042, F1: 0.4576\n",
      "K-Nearest Neighbors Classifier - Accuracy: 0.4854, Precision: 0.4733, Recall: 0.4854, F1: 0.4621\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (make sure the CSV file is in the same directory as your notebook/script)\n",
    "df = pd.read_csv('winequality-red.csv')  # Adjust the file name if necessary\n",
    "\n",
    "\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier Evaluation:\")\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt, average='weighted', zero_division=1)\n",
    "recall_dt = recall_score(y_test, y_pred_dt, average='weighted', zero_division=1)\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_dt:.2f}\") #.2f is 2 digits after the decimal point\n",
    "print(f\"Precision: {precision_dt:.2f}\")\n",
    "print(f\"Recall: {recall_dt:.2f}\")\n",
    "print(f\"F1 Score: {f1_dt:.2f}\")\n",
    "\n",
    "# Evaluate Support Vector Classifier\n",
    "print(\"\\nSupport Vector Classifier Evaluation:\")\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "recall_svc = recall_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "f1_svc = f1_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_svc:.2f}\")\n",
    "print(f\"Precision: {precision_svc:.2f}\")\n",
    "print(f\"Recall: {recall_svc:.2f}\")\n",
    "print(f\"F1 Score: {f1_svc:.2f}\")\n",
    "\n",
    "# Evaluate K-Nearest Neighbors Classifier\n",
    "print(\"\\nK-Nearest Neighbors Classifier Evaluation:\")\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_knn:.2f}\")\n",
    "print(f\"Precision: {precision_knn:.2f}\")\n",
    "print(f\"Recall: {recall_knn:.2f}\")\n",
    "print(f\"F1 Score: {f1_knn:.2f}\")\n",
    "\n",
    "# Compare Models\n",
    "print(\"\\n Model Comparison:\")\n",
    "print(f\"Decision Tree Classifier - Accuracy: {accuracy_dt:.4f}, Precision: {precision_dt:.4f}, Recall: {recall_dt:.4f}, F1: {f1_dt:.4f}\")\n",
    "print(f\"Support Vector Classifier - Accuracy: {accuracy_svc:.4f}, Precision: {precision_knn:.4f}, Recall: {recall_svc:.4f}, F1: {f1_svc:.4f}\")\n",
    "print(f\"K-Nearest Neighbors Classifier - Accuracy: {accuracy_knn:.4f}, Precision: {precision_knn:.4f}, Recall: {recall_knn:.4f}, F1: {f1_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24016506-75c4-498b-8229-5d1b46babf68",
   "metadata": {},
   "source": [
    "## 7. Other evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7396a4a-fc29-4094-83fc-94e3361e8717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 7.Other revolution method\n",
      "\n",
      "Decision Tree Classifier Confusion Matrix:\n",
      "[[  0   0   1   0   0   0]\n",
      " [  0   1  10   5   1   0]\n",
      " [  1   8 126  58   2   0]\n",
      " [  0   5  48 121  26   0]\n",
      " [  0   1   6  26  26   2]\n",
      " [  0   0   0   3   2   1]]\n",
      "\n",
      "Decision Tree Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.07      0.06      0.06        17\n",
      "           5       0.66      0.65      0.65       195\n",
      "           6       0.57      0.60      0.59       200\n",
      "           7       0.46      0.43      0.44        61\n",
      "           8       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.57       480\n",
      "   macro avg       0.35      0.32      0.33       480\n",
      "weighted avg       0.57      0.57      0.57       480\n",
      "\n",
      "\n",
      "Support Vector Classifier Confusion Matrix:\n",
      "[[  0   0   0   1   0   0]\n",
      " [  0   0   3  14   0   0]\n",
      " [  0   0  99  96   0   0]\n",
      " [  0   0  58 142   0   0]\n",
      " [  0   0   5  55   1   0]\n",
      " [  0   0   1   5   0   0]]\n",
      "\n",
      "Support Vector Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00        17\n",
      "           5       0.60      0.51      0.55       195\n",
      "           6       0.45      0.71      0.55       200\n",
      "           7       1.00      0.02      0.03        61\n",
      "           8       1.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50       480\n",
      "   macro avg       0.84      0.21      0.19       480\n",
      "weighted avg       0.61      0.50      0.46       480\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classifier Confusion Matrix:\n",
      "[[  0   0   1   0   0   0]\n",
      " [  0   1   7   9   0   0]\n",
      " [  0   1 126  64   4   0]\n",
      " [  0   2  89  97  12   0]\n",
      " [  0   0  18  34   9   0]\n",
      " [  0   0   1   4   1   0]]\n",
      "\n",
      "K-Nearest Neighbors Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       0.25      0.06      0.10        17\n",
      "           5       0.52      0.65      0.58       195\n",
      "           6       0.47      0.48      0.48       200\n",
      "           7       0.35      0.15      0.21        61\n",
      "           8       1.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.49       480\n",
      "   macro avg       0.60      0.22      0.23       480\n",
      "weighted avg       0.47      0.49      0.46       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (make sure the CSV file is in the same directory as your notebook/script)\n",
    "df = pd.read_csv('winequality-red.csv')  # Adjust the file name if necessary\n",
    "\n",
    "\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\\n 7.Other revolution method\")\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "print(\"\\nDecision Tree Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, zero_division=1))\n",
    "\n",
    "# Evaluate Support Vector Classifier\n",
    "print(\"\\nSupport Vector Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svc))\n",
    "\n",
    "print(\"\\nSupport Vector Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svc, zero_division=1))\n",
    "\n",
    "# Evaluate K-Nearest Neighbors Classifier\n",
    "print(\"\\nK-Nearest Neighbors Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c3d0d-7247-48af-84ed-b2440548b25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
